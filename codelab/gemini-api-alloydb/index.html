
<!doctype html>

<html>
<head>
  <meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, user-scalable=yes">
  <meta name="theme-color" content="#4F7DC9">
  <meta charset="UTF-8">
  <title>üõ†Ô∏è 
Product Feedback Accelerator Workshop</title>
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Code+Pro:400|Roboto:400,300,400italic,500,700|Roboto+Mono">
  <link rel="stylesheet" href="//fonts.googleapis.com/icon?family=Material+Icons">
  <link rel="stylesheet" href="https://storage.googleapis.com/claat-public/codelab-elements.css">
  <style>
    .success {
      color: #1e8e3e;
    }
    .error {
      color: red;
    }
  </style>
</head>
<body>
  <google-codelab-analytics gaid="UA-49880327-14" ga4id=""></google-codelab-analytics>
  <google-codelab codelab-gaid=""
                  codelab-ga4id=""
                  id="gemini-api-alloydb"
                  title="üõ†Ô∏è 
Product Feedback Accelerator Workshop"
                  environment="web"
                  feedback-link="">
    
      <google-codelab-step label="Introduction" duration="1">
        <p><strong>rapidly analyze and respond to user feedback</strong> for products. You&#39;ll learn how to leverage Google Cloud services and the Gemini API/Vertex AI to transform raw customer ratings and comments into actionable insights, significantly improving customer response times and overall user satisfaction.</p>
<h2 is-upgraded>codelabs</h2>
<p>https://nuno-joao-andrade.github.io/gemini-api-alloydb/codelab/gemini-api-alloydb/</p>
<h2 is-upgraded>github repo</h2>
<p>https://github.com/nuno-joao-andrade/gemini-api-alloydb/</p>
<h2 is-upgraded><strong>What You Will Build</strong></h2>
<p>You will create a comprehensive back-end service that automates the processing of user feedback. The core functions of this API include:</p>
<ul>
<li><strong>Ratings Retrieval:</strong> Fetching and consolidating user ratings and reviews for various products.</li>
<li><strong>AI-Powered Comment Evaluation &amp; Categorization:</strong> Utilizing the <strong>Gemini API / Vertex AI</strong> to analyze the sentiment, topic, and intent of each comment. <ul>
<li><strong>Sentiment Analysis:</strong> Determining if the comment is positive, negative, or neutral.</li>
<li><strong>Topic/Intent Categorization:</strong> Automatically assigning comments to relevant categories (e.g., &#34;Bug Report,&#34; &#34;Feature Request,&#34; &#34;Delivery Issue,&#34; &#34;General Praise&#34;).</li>
</ul>
</li>
<li><strong>Suggested Replies Generation:</strong> Generating contextually appropriate and personalized response drafts for comments, drastically reducing the manual effort required for customer service teams.</li>
<li><strong>Performance Analytics &amp; Testing:</strong> Analyzing rating trends and comment processing metrics to continuously <strong>improve response time</strong> for high-priority feedback. <strong>We will also generate synthetic feedback data to populate the database and create performance testing scripts to stress-test the deployed services.</strong></li>
</ul>
<h2 is-upgraded><strong>Key Technologies Used &amp; Documentation</strong></h2>
<table>
<tr><td colspan="1" rowspan="1"><p>Technology</p>
</td><td colspan="1" rowspan="1"><p>Role in the Workshop</p>
</td><td colspan="1" rowspan="1"><p>Documentation Link</p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>AlloyDB for PostgreSQL</strong></p>
</td><td colspan="1" rowspan="1"><p>The high-performance, fully managed database for storing and querying product data, user ratings, and the resulting AI analysis/categorizations.</p>
</td><td colspan="1" rowspan="1"><p><a href="https://cloud.google.com/alloydb/docs" target="_blank">AlloyDB Documentation</a></p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>Node.js</strong></p>
</td><td colspan="1" rowspan="1"><p>The runtime environment for building the fast, scalable, and event-driven API back-end.</p>
</td><td colspan="1" rowspan="1"><p><a href="https://nodejs.org/en" target="_blank">Node.js</a> <br> <a href="https://nodejs.org/en/docs" target="_blank">Node.js Ref. Docs</a></p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>Cloud Run</strong></p>
</td><td colspan="1" rowspan="1"><p>The serverless compute platform used to deploy the Node.js API, providing automatic scaling and a highly efficient operational environment.</p>
</td><td colspan="1" rowspan="1"><p><a href="https://cloud.google.com/run/docs" target="_blank">Cloud Run Documentation</a></p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>Gemini API / Vertex AI</strong></p>
</td><td colspan="1" rowspan="1"><p>The engine for advanced machine learning tasks, handling all the heavy lifting for sentiment analysis, comment categorization, and suggested reply generation.</p>
</td><td colspan="1" rowspan="1"><p><a href="https://cloud.google.com/vertex-ai/generative-ai/docs/learn/overview" target="_blank">Gemini API Documentation</a></p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>Gemini-CLI (Command Line Interface)</strong></p>
</td><td colspan="1" rowspan="1"><p><strong>We will leverage the Gemini-CLI to accelerate development by generating boilerplate code (Node.js), database schema scripts (SQL for AlloyDB), and realistic-looking fake data.</strong></p>
</td><td colspan="1" rowspan="1"><p><a href="https://ai.google.dev/docs" target="_blank">Gemini API Developer Site</a></p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>hey or ab (optional for performance testing only)</strong></p>
</td><td colspan="1" rowspan="1"><p>**hey is a tiny program that sends some load to a web application. / apache benchmark **</p>
</td><td colspan="1" rowspan="1"><p><a href="https://github.com/rakyll/hey" target="_blank">hey Site</a> / <a href="https://httpd.apache.org/docs/2.4/programs/ab.html" target="_blank">ab Site</a></p>
</td></tr>
</table>
<h2 is-upgraded><strong>Learning Objectives</strong></h2>
<p>By the end of this workshop, you will know how to:</p>
<ul>
<li>Design a modern, scalable API architecture using Node.js and Cloud Run.</li>
<li>Integrate the Gemini API/Vertex AI for natural language processing (NLP) tasks like classification and content generation.</li>
<li>Utilize AlloyDB effectively for transactional and analytical workloads.</li>
<li>Build a pipeline that turns unstructured data (customer comments) into structured, prioritized, and actionable data.</li>
<li><strong>Implement data generation strategies and create load testing scripts to benchmark the system&#39;s performance.</strong></li>
<li><strong>Use the power of generative AI via the Gemini-CLI to rapidly prototype and scaffold application components, significantly boosting development speed.</strong></li>
</ul>
<h2 is-upgraded><strong>Google Cloud Authentication</strong></h2>
<p>Before you begin, you need to authenticate with Google Cloud. Run the following commands in your terminal:</p>
<ol type="1">
<li><strong>Login to your Google Cloud account:</strong><pre><code language="language-bash" class="language-bash">gcloud auth login
</code></pre>
</li>
<li><strong>Set up Application Default Credentials:</strong><pre><code language="language-bash" class="language-bash">gcloud auth application-default login
</code></pre>
</li>
<li><strong>Set your Google Cloud project:</strong><pre><code language="language-bash" class="language-bash">gcloud config set project [YOUR_PROJECT_ID]
</code></pre>
<em>Replace </em><em><code>[YOUR_PROJECT_ID]</code></em><em> with your actual Google Cloud project ID.</em></li>
<li><strong>Download alloydb proxy: (linux)</strong><pre><code language="language-bash" class="language-bash">    wget https://storage.googleapis.com/alloydb-auth-proxy/v1.13.6/alloydb-auth-proxy.linux.amd64 -O alloydb-auth-proxy
</code></pre>
<pre><code language="language-bash" class="language-bash">    chmod +x alloydb-auth-proxy
</code></pre>
</li>
</ol>


      </google-codelab-step>
    
      <google-codelab-step label="Module 0: Setup and Environment Preparation  üõ†Ô∏è" duration="10">
        <p>This module ensures all necessary tools and credentials are in place before starting development.</p>
<table>
<tr><td colspan="1" rowspan="1"><p>Step</p>
</td><td colspan="1" rowspan="1"><p>Instruction</p>
</td><td colspan="1" rowspan="1"><p>Details</p>
</td><td colspan="1" rowspan="1"><p>Resources</p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>0.1</strong></p>
</td><td colspan="1" rowspan="1"><p><strong>System Requirements Check</strong></p>
</td><td colspan="1" rowspan="1"><p>Ensure <strong>Node.js ($\ge$ 22)</strong>, <strong>npm ($\ge$ 10)</strong>, and the <strong>gcloud CLI</strong>, <strong>gemini-cli</strong> , <strong>alloydb-auth-proxy</strong> are installed.</p>
</td><td colspan="1" rowspan="1"><p><strong>Action:</strong> Install all dependencies</p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>0.2</strong></p>
</td><td colspan="1" rowspan="1"><p><strong>AlloyDB Proxy</strong></p>
</td><td colspan="1" rowspan="1"><p>Download and set up the AlloyDB Auth Proxy for local connectivity.</p>
</td><td colspan="1" rowspan="1"><p><a href="https://docs.cloud.google.com/alloydb/docs/auth-proxy/connect" target="_blank">AlloyDB Proxy Docs</a></p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>0.3</strong></p>
</td><td colspan="1" rowspan="1"><p><strong>Gemini API Key / Vertex AI</strong></p>
</td><td colspan="1" rowspan="1"><p>Generate and obtain your Gemini API key (or Vertex AI credentials).</p>
</td><td colspan="1" rowspan="1"><p><a href="https://docs.cloud.google.com/vertex-ai/generative-ai/docs/start/api-keys?usertype=expressmode" target="_blank">Vertex AI Credentials Docs</a> <a href="https://docs.cloud.google.com/vertex-ai/generative-ai/docs/sdks/overview#googlegenaisdk_quickstart-nodejs_genai_sdk" target="_blank">API Reference</a></p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>0.4</strong></p>
</td><td colspan="1" rowspan="1"><p><strong>Set Environment Variables</strong></p>
</td><td colspan="1" rowspan="1"><p>Define required credentials and project settings in your terminal session.</p>
</td><td colspan="1" rowspan="1"><p><code>export GOOGLE_API_KEY=...</code> <br> <code>export GOOGLE_GENAI_USE_VERTEXAI="true"</code> <br> <code>export GOOGLE_CLOUD_PROJECT="..."</code></p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>0.5</strong></p>
</td><td colspan="1" rowspan="1"><p><strong>Create AlloyDB Instance</strong></p>
</td><td colspan="1" rowspan="1"><p>Provision the instance, create the database (<code>items</code>), and the application user (<code>items</code> / <code>!items123</code>).</p>
</td><td colspan="1" rowspan="1"><p>Go to the [https://console.cloud.google.com/] (https://console.cloud.google.com/), search for alloydb and create the instance cluster. <br><br> <strong>1) Instance Specs <br> Cluster Password:</strong> create a strong password <br> <strong>VPC :</strong> Use the default, <br> <strong>Allow external IP</strong>: Without any network allowed. (In the dev environment only, to allow connection via proxy to test the code.) <br> <strong>Check SSL configuration (only important for step 5) <br> <br> 2) Create Database + User:</strong> Database Name: <code>items</code>; Database User: <code>items</code> / <strong>create a strong password</strong> and execute the grant_privileges.sql in the AlloyDB studio with postgres user, <br></p>
</td></tr>
</table>


      </google-codelab-step>
    
      <google-codelab-step label="Module 1: Database Setup and AI-Driven Data Generation ü§ñ" duration="10">
        <p>We use the <strong>Gemini-CLI</strong> to instantly generate the SQL schema and realistic synthetic data.</p>
<table>
<tr><td colspan="1" rowspan="1"><p>Step</p>
</td><td colspan="1" rowspan="1"><p>Instruction</p>
</td><td colspan="1" rowspan="1"><p>Description</p>
</td><td colspan="1" rowspan="1"><p>Gemini-CLI Prompt / Action</p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>1.1</strong></p>
</td><td colspan="1" rowspan="1"><p><strong>Generate DB Structure (SQL)</strong></p>
</td><td colspan="1" rowspan="1"><p>Use the CLI to create the SQL script for all sequences and tables.</p>
</td><td colspan="1" rowspan="1"><p><strong>Prompt: </strong><code>create a script to create the following elements in alloydb: 1) Sequences: items, orders, order_items, ratings, users. 2) Tables: Items (item_id, item_description, item_value), orders (order_id, create_date, status, user_id), order_items (order_items_id, order_id, item_id, quantity), ratings (rating_id, value, comments, user_id, order_items_id), users (user_id, name, email, status).</code></p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>1.1a</strong></p>
</td><td colspan="1" rowspan="1"><p><strong>Launch AlloyDB Auth Proxy</strong></p>
</td><td colspan="1" rowspan="1"><p>Start the Auth Proxy to connect to your AlloyDB instance locally.</p>
</td><td colspan="1" rowspan="1"><p><strong>Action: </strong><code>./alloydb-auth-proxy -p 5433 INSTANCE_CONNECTION_NAME</code> (replace with your instance name)</p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>1.2</strong></p>
</td><td colspan="1" rowspan="1"><p><strong>Execute Schema Script</strong></p>
</td><td colspan="1" rowspan="1"><p>Run the generated <code>setup_alloydb.sql</code> script on your AlloyDB instance.</p>
</td><td colspan="1" rowspan="1"><p><strong>Action: </strong><code>psql -h 127.0.0.1 -p 5433 -d items -U items -W -f setup_alloydb.sql</code></p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>1.3</strong></p>
</td><td colspan="1" rowspan="1"><p><strong>Generate Synthetic Data</strong></p>
</td><td colspan="1" rowspan="1"><p>Generate a massive amount of correlated data, focusing on realistic text for the <code>comments</code> column.</p>
</td><td colspan="1" rowspan="1"><p><strong>Prompt: ADJUST TO THE CAPACITY OF THE INSTANCE CREATED </strong><code>generate a populate script to insert correlated sample data for all tables with the following volumes: items - 50k, users - 50k, orders - 500k, order_items - 1M, ratings - 100k. CRUCIALLY, for the ratings 'comments' column, insert meaningful, realistic product review text (e.g., bug reports, feature requests, praise).</code></p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>1.4</strong></p>
</td><td colspan="1" rowspan="1"><p><strong>Execute Data Script</strong></p>
</td><td colspan="1" rowspan="1"><p>Run the generated data insertion script to populate the database for testing.</p>
</td><td colspan="1" rowspan="1"><p><strong>Action:</strong> Execute the large data insertion script. <code>psql -h 127.0.0.1 -p 5433 -d items -U items -W -f populate_alloydb.sql</code></p>
</td></tr>
</table>


      </google-codelab-step>
    
      <google-codelab-step label="Module 2: API Scaffolding and Connection üíª" duration="15">
        <p>We use the <strong>Gemini-CLI</strong> to quickly scaffold the Node.js API structure and connection logic.</p>
<table>
<tr><td colspan="1" rowspan="1"><p>Step</p>
</td><td colspan="1" rowspan="1"><p>Instruction</p>
</td><td colspan="1" rowspan="1"><p>Description</p>
</td><td colspan="1" rowspan="1"><p>Gemini-CLI Prompt / Action</p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>2.1</strong></p>
</td><td colspan="1" rowspan="1"><p><strong>Project Setup &amp; Structure</strong></p>
</td><td colspan="1" rowspan="1"><p>Initialize the project, create folders, and scaffold the basic Express server and CRUD APIs.</p>
</td><td colspan="1" rowspan="1"><p><strong>Prompt: </strong><code>follow these steps: 1) do npm init. 2) create folder structure: 'database_scripts', 'apis', 'lib'. 3) move db scripts to 'database_scripts'. 4) create a Node.js Express server with basic CRUD API endpoints for all tables structured in the SQL script. Place API logic in the 'apis' folder.</code></p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>2.2</strong></p>
</td><td colspan="1" rowspan="1"><p><strong>Configure Local Environment</strong></p>
</td><td colspan="1" rowspan="1"><p>Generate <code>.gitignore</code> and the connection <code>.env</code> file, and update <code>package.json</code>.</p>
</td><td colspan="1" rowspan="1"><p><strong>Prompt: </strong><code>1) Create a .gitignore for this project. 2) Create a .env file with these values: host: localhost, port: 5433, user: items, password: !items123, database: items, don't forget to prefix the env vars should start with DB_ 3) Create a 'start:local' script in package.json to load the .env file and start the server.</code></p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>2.3</strong></p>
</td><td colspan="1" rowspan="1"><p><strong>Connect to AlloyDB</strong></p>
</td><td colspan="1" rowspan="1"><p>Update all generated API files to establish and use a connection pool to AlloyDB using the <code>.env</code> variables.</p>
</td><td colspan="1" rowspan="1"><p><strong>Prompt:</strong> Implement the PostgreSQL driver (e.g., <code>pg</code>) connection logic in the <code>lib</code> folder and integrate it into the <code>apis</code>.</p>
</td></tr>
</table>


      </google-codelab-step>
    
      <google-codelab-step label="Module 3: Core API Development and Performance Testing ‚ö°" duration="20">
        <p>We refine data access and introduce performance testing.</p>
<table>
<tr><td colspan="1" rowspan="1"><p>Step</p>
</td><td colspan="1" rowspan="1"><p>Instruction</p>
</td><td colspan="1" rowspan="1"><p>Description</p>
</td><td colspan="1" rowspan="1"><p>Gemini-CLI Prompt / Action</p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>3.1</strong></p>
</td><td colspan="1" rowspan="1"><p><strong>Refine Basic Endpoints (Limit)</strong></p>
</td><td colspan="1" rowspan="1"><p>Update all GET APIs to support a <code>limit</code> parameter to restrict results.</p>
</td><td colspan="1" rowspan="1"><p><strong>Prompt:</strong> Modify the API code to accept <code>?limit=</code> and apply <code>LIMIT $1</code> to the SQL.</p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>3.2</strong></p>
</td><td colspan="1" rowspan="1"><p><strong>Refine Basic Endpoints (Pagination)</strong></p>
</td><td colspan="1" rowspan="1"><p>Enhance all GET APIs to support full pagination (<code>limit</code> and <code>offset</code>).</p>
</td><td colspan="1" rowspan="1"><p><strong>Prompt: </strong><code>go ahead and change all the get apis to support both the 'limit' and 'offset' parameters for full pagination capabilities.</code></p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>3.3</strong></p>
</td><td colspan="1" rowspan="1"><p><strong>Create Complex APIs</strong></p>
</td><td colspan="1" rowspan="1"><p>Build an API combining multiple entities (relational queries).</p>
</td><td colspan="1" rowspan="1"><p><strong>Prompt: </strong><code>create a complex API combining entities, specifically an endpoint to return a user's entire order history, detailing all purchased items per order.</code></p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>3.4</strong></p>
</td><td colspan="1" rowspan="1"><p><strong>Setup Hey Test Scripts</strong></p>
</td><td colspan="1" rowspan="1"><p>Create a folder and a script to load-test the API performance.</p>
</td><td colspan="1" rowspan="1"><p><strong>Prompt:</strong> Create <code>testing_scripts/test_ratings_performance.sh</code> to run <code>hey -n 5000 -c 50</code> against the <code>/api/ratings?limit=10</code> endpoint, accepting the host as an optional parameter.</p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>3.5</strong></p>
</td><td colspan="1" rowspan="1"><p><strong>Test Local Performance</strong></p>
</td><td colspan="1" rowspan="1"><p>Run the performance test script against your local server.</p>
</td><td colspan="1" rowspan="1"><p><strong>Action: </strong><code>./testing_scripts/test_ratings_performance.sh http://localhost:3000</code></p>
</td></tr>
</table>


      </google-codelab-step>
    
      <google-codelab-step label="Module 4: AI Integration for Feedback Analysis üß†" duration="20">
        <p>This is the core value-add module, integrating the Gemini API for advanced NLP.</p>
<table>
<tr><td colspan="1" rowspan="1"><p>Step</p>
</td><td colspan="1" rowspan="1"><p>Instruction</p>
</td><td colspan="1" rowspan="1"><p>Description</p>
</td><td colspan="1" rowspan="1"><p>Gemini-CLI Prompt / Action</p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>4.1</strong></p>
</td><td colspan="1" rowspan="1"><p><strong>Simple Analytics Endpoint</strong></p>
</td><td colspan="1" rowspan="1"><p>Create a traditional database query for simple aggregation.</p>
</td><td colspan="1" rowspan="1"><p><strong>Prompt: </strong><code>In the ratings API, create a special endpoint: '/api/items/:item_id/average-rating' that returns the calculated average rating for a particular item ID using pure SQL aggregation. </code></p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>4.2</strong></p>
</td><td colspan="1" rowspan="1"><p><strong>AI-Powered Summarization</strong></p>
</td><td colspan="1" rowspan="1"><p>Use the Gemini API to analyze comments and identify pain points.</p>
</td><td colspan="1" rowspan="1"><p><strong>Prompt: </strong><code>Create a new endpoint: '/api/items/:item_id/top-complaints'. This endpoint must fetch all comments for the given item ID from the AlloyDB 'ratings' table. Then, it must use the Gemini API to analyze these comments and return a summary of the top 3 most frequent complaints or recurring issues found in the text. use @google/genai package with this constructor: new GoogleGenAI({vertexai: true, apiKey:process.env.GOOGLE_API_KEY}); </code></p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>4.3</strong></p>
</td><td colspan="1" rowspan="1"><p><strong>Test AI Endpoint</strong></p>
</td><td colspan="1" rowspan="1"><p>Test the new endpoint and observe the AI-generated insights.</p>
</td><td colspan="1" rowspan="1"><p><strong>Action:</strong> Run a <code>curl</code> command against the new AI endpoint and analyze the output, noting the speed of insight generation.</p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>4.4</strong></p>
</td><td colspan="1" rowspan="1"><p><strong>Test ALL Endpoints</strong></p>
</td><td colspan="1" rowspan="1"><p>Creation of a global test script</p>
</td><td colspan="1" rowspan="1"><p><strong>Prompt:</strong> create a script that call curl with to test all the endpoints.</p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>4.5</strong></p>
</td><td colspan="1" rowspan="1"><p><strong>Generate Open API interface (optional)</strong></p>
</td><td colspan="1" rowspan="1"><p>Creation of a global test script</p>
</td><td colspan="1" rowspan="1"><p><strong>Prompt:</strong> Generate a open api interface for all the endpoints</p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>4.6</strong></p>
</td><td colspan="1" rowspan="1"><p><strong>Generate Open API interface (optional)</strong></p>
</td><td colspan="1" rowspan="1"><p>Creation of a global test script</p>
</td><td colspan="1" rowspan="1"><p><strong>Prompt:</strong> in the ratings api methods put and post, add a functionality to push a message to a pub/sub topic called &#34;negative-ratings&#34;, if a comment is negative, in the payload include a suggested a reply to the user. use @google/genai package use @google/genai package with this constructor: new GoogleGenAI({vertexai: true, apiKey:process.env.GOOGLE_API_KEY});</p>
</td></tr>
</table>


      </google-codelab-step>
    
      <google-codelab-step label="Module 5: Deployment to Cloud Run (optional) üöÄ" duration="15">
        <p>This module focuses on preparing the application for deployment and deploying it to Google Cloud Run.</p>
<table>
<tr><td colspan="1" rowspan="1"><p>Step</p>
</td><td colspan="1" rowspan="1"><p>Instruction</p>
</td><td colspan="1" rowspan="1"><p>Description</p>
</td><td colspan="1" rowspan="1"><p>Gemini-CLI Prompt / Action</p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>5.1</strong></p>
</td><td colspan="1" rowspan="1"><p><strong>Containerize Application</strong></p>
</td><td colspan="1" rowspan="1"><p>Create a Dockerfile to package the Node.js application.</p>
</td><td colspan="1" rowspan="1"><p><strong>Prompt: </strong><code>create a dockerfile for the nodejs application</code></p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>5.2</strong></p>
</td><td colspan="1" rowspan="1"><p><strong>Build and Push Docker Image</strong></p>
</td><td colspan="1" rowspan="1"><p>Build the Docker image and push it to Google Container Registry (GCR) or Artifact Registry.</p>
</td><td colspan="1" rowspan="1"><p><strong>Action: </strong><code>gcloud builds submit --tag gcr.io/[PROJECT-ID]/alloydb-api</code></p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>5.3</strong></p>
</td><td colspan="1" rowspan="1"><p><strong>Deploy to Cloud Run</strong></p>
</td><td colspan="1" rowspan="1"><p>Deploy the containerized application to Google Cloud Run.</p>
</td><td colspan="1" rowspan="1"><p><strong>Action: </strong><code>gcloud run deploy alloydb-api --image gcr.io/[PROJECT-ID]/alloydb-api --platform managed --region [REGION] --allow-unauthenticated</code></p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>5.4</strong></p>
</td><td colspan="1" rowspan="1"><p><strong>Configure Cloud Run to AlloyDB</strong></p>
</td><td colspan="1" rowspan="1"><p>Connect the Cloud Run service to AlloyDB instance via a Serverless VPC Access connector.</p>
</td><td colspan="1" rowspan="1"><p><strong>Action:</strong> Configure the AlloyDB connection string with the private IP and ensure Serverless VPC Access is set up for Cloud Run.  Check the SSL true in the connection to the AlloyDB</p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p><strong>5.5</strong></p>
</td><td colspan="1" rowspan="1"><p><strong>Test Deployed API</strong></p>
</td><td colspan="1" rowspan="1"><p>Verify the deployed API endpoints are working correctly.</p>
</td><td colspan="1" rowspan="1"><p><strong>Action:</strong> Use <code>curl</code> or the <code>test_all_apis.sh</code> script against the Cloud Run URL.</p>
</td></tr>
</table>
<h2 is-upgraded><strong>Production Readiness &amp; Security Best Practices</strong> üõ°Ô∏è</h2>
<p>While this workshop focuses on rapid development and functionality, moving to a production environment requires strict adherence to security and operational best practices. The following tasks are <strong>mandatory</strong> for a production-grade deployment:</p>
<ul>
<li>[ ] <strong>Cloud Run Authentication:</strong> Disable <code>allow-unauthenticated</code> and enforce IAM-based authentication for all service invocations to secure your API.</li>
<li>[ ] <strong>Ingress &amp; Load Balancing:</strong> Implement a Global External Application Load Balancer with Cloud Armor to handle traffic management, DDoS protection, and WAF rules.</li>
<li>[ ] <strong>Internal Traffic Only:</strong> Configure Cloud Run ‚ÄòIngress Control&#39; to ‚ÄòInternal&#39; or ‚ÄòInternal and Cloud Load Balancing&#39; to prevent direct public access to the service URL.</li>
<li>[ ] <strong>Least Privilege Service Accounts:</strong> Create a dedicated Service Account for the Cloud Run service with the minimum required permissions (e.g., <code>Cloud SQL Client</code>, <code>Pub/Sub Publisher</code>, <code>Vertex AI User</code>) instead of using the default Compute Engine service account.</li>
<li>[ ] <strong>API Management (Apigee):</strong> (Optional) Deploy Apigee or API Gateway in front of your backend services for advanced rate limiting, quota management, analytics, and developer portal capabilities.</li>
<li>[ ] <strong>Secret Management:</strong> Store sensitive configuration (DB passwords, API keys) in <strong>Secret Manager</strong> and mount them as environment variables in Cloud Run, rather than hardcoding them.</li>
<li>[ ] <strong>Force SSL and disable external IP:</strong> In the connection of the database make sure you force and disable external IP.</li>
</ul>
<p><strong>Ready to accelerate your customer feedback loop? Let&#39;s get started!</strong></p>


      </google-codelab-step>
    
  </google-codelab>

  <script src="https://storage.googleapis.com/claat-public/native-shim.js"></script>
  <script src="https://storage.googleapis.com/claat-public/custom-elements.min.js"></script>
  <script src="https://storage.googleapis.com/claat-public/prettify.js"></script>
  <script src="https://storage.googleapis.com/claat-public/codelab-elements.js"></script>
  <script src="//support.google.com/inapp/api.js"></script>

</body>
</html>
